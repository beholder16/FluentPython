{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b444b102df4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mProject\u001b[0m \u001b[0mURL\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0msolarisailab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0marchives\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2482\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\"\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "GAN(Generative Adversarial Networks)을 이용한 MNIST 데이터 생성\n",
    "Reference : https://github.com/TengdaHan/GAN-TensorFlow\n",
    "Author : solaris33\n",
    "Project URL : http://solarisailab.com/archives/2482\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "# MNIST 데이터를 불러옵니다.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "# 생성된 MNIST 이미지를 8x8 Grid로 보여주는 plot 함수를 정의합니다.\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(8, 8)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample.reshape(28, 28))\n",
    "    return fig\n",
    "# 설정값들을 선언합니다.\n",
    "num_epoch = 100000\n",
    "batch_size = 64\n",
    "num_input = 28 * 28\n",
    "num_latent_variable = 100\n",
    "num_hidden = 128\n",
    "learning_rate = 0.001\n",
    "# 플레이스 홀더를 선언합니다.\n",
    "X = tf.placeholder(tf.float32, [None, num_input])               # 인풋 이미지\n",
    "z = tf.placeholder(tf.float32, [None, num_latent_variable])     # 인풋 Latent Variable\n",
    "# Generator 변수들 설정 \n",
    "# 100 -> 128 -> 784\n",
    "with tf.variable_scope('generator'):\n",
    "# 히든 레이어 파라미터 \n",
    "    G_W1 = tf.Variable(tf.random_normal(shape=[num_latent_variable, num_hidden], stddev=5e-2)) \n",
    "    G_b1 = tf.Variable(tf.constant(0.1, shape=[num_hidden]))\n",
    "# 아웃풋 레이어 파라미터\n",
    "    G_W2 = tf.Variable(tf.random_normal(shape=[num_hidden, num_input], stddev=5e-2))   \n",
    "    G_b2 = tf.Variable(tf.constant(0.1, shape=[num_input]))\n",
    "# Discriminator 변수들 설정 \n",
    "# 784 -> 128 -> 1\n",
    "with tf.variable_scope('discriminator'):\n",
    "# 히든 레이어 파라미터\n",
    "    D_W1 = tf.Variable(tf.random_normal(shape=[num_input, num_hidden], stddev=5e-2))   \n",
    "    D_b1 = tf.Variable(tf.constant(0.1, shape=[num_hidden]))\n",
    "# 아웃풋 레이어 파라미터\n",
    "    D_W2 = tf.Variable(tf.random_normal(shape=[num_hidden, 1], stddev=5e-2))   \n",
    "    D_b2 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "# Generator를 생성하는 함수를 정의합니다.\n",
    "# Inputs:\n",
    "#   X : 인풋 Latent Variable\n",
    "# Output:\n",
    "#   generated_mnist_image : 생성된 MNIST 이미지\n",
    "def build_generator(X):\n",
    "    hidden_layer = tf.nn.relu((tf.matmul(X, G_W1) + G_b1))\n",
    "    output_layer = tf.matmul(hidden_layer, G_W2) + G_b2\n",
    "    generated_mnist_image = tf.nn.sigmoid(output_layer)\n",
    "    return generated_mnist_image\n",
    "# Discriminator를 생성하는 함수를 정의합니다.\n",
    "# Inputs:\n",
    "#   X : 인풋 이미지\n",
    "# Output:\n",
    "#   predicted_value : Discriminator가 판단한 True(1) or Fake(0)\n",
    "#   logits : sigmoid를 씌우기전의 출력값\n",
    "def build_discriminator(X):\n",
    "    hidden_layer = tf.nn.relu((tf.matmul(X, D_W1) + D_b1))\n",
    "    logits = tf.matmul(hidden_layer, D_W2) + D_b2\n",
    "    predicted_value = tf.nn.sigmoid(logits)\n",
    "    return predicted_value, logits\n",
    "# 생성자(Generator)를 선언합니다.\n",
    "G = build_generator(z)\n",
    "# 구분자(Discriminator)를 선언합니다.\n",
    "D_real, D_real_logits = build_discriminator(X)  # D(x)\n",
    "D_fake, D_fake_logits = build_discriminator(G)  # D(G(z))\n",
    "# Discriminator의 손실 함수를 정의합니다.\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real_logits)))    # log(D(x))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake_logits)))   # log(1-D(G(z)))\n",
    "d_loss = d_loss_real + d_loss_fake  # log(D(x)) + log(1-D(G(z)))\n",
    "# Generator의 손실 함수를 정의합니다.\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake_logits)))         # log(D(G(z))\n",
    "# 전체 파라미터를 Discriminator와 관련된 파라미터와 Generator와 관련된 파라미터로 나눕니다.\n",
    "tvar = tf.trainable_variables()\n",
    "dvar = [var for var in tvar if 'discriminator' in var.name]\n",
    "gvar = [var for var in tvar if 'generator' in var.name]\n",
    "# Discriminator와 Generator의 Optimizer를 정의합니다.\n",
    "d_train_step = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=dvar)\n",
    "g_train_step = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=gvar)\n",
    "# 생성된 이미지들을 저장할 generated_outputs 폴더를 생성합니다.\n",
    "num_img = 0\n",
    "if not os.path.exists('generated_output/'):\n",
    "    os.makedirs('generated_output/')\n",
    "with tf.Session() as sess:\n",
    "# 변수들에 초기값을 할당합니다.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "# num_epoch 횟수만큼 최적화를 수행합니다.\n",
    "for i in range(num_epoch):\n",
    "# MNIST 이미지를 batch_size만큼 불러옵니다. \n",
    "    batch_X, _ = mnist.train.next_batch(batch_size)\n",
    "# Latent Variable의 인풋으로 사용할 noise를 Uniform Distribution에서 batch_size만큼 샘플링합니다.\n",
    "    batch_noise = np.random.uniform(-1., 1., [batch_size, 100])\n",
    "# 500번 반복할때마다 생성된 이미지를 저장합니다.\n",
    "if i % 500 == 0:\n",
    "    samples = sess.run(G, feed_dict={z: np.random.uniform(-1., 1., [64, 100])})\n",
    "    fig = plot(samples)\n",
    "    plt.savefig('generated_output/%s.png' % str(num_img).zfill(3), bbox_inches='tight')\n",
    "    num_img += 1\n",
    "    plt.close(fig)\n",
    "# Discriminator 최적화를 수행하고 Discriminator의 손실함수를 return합니다.\n",
    "    _, d_loss_print = sess.run([d_train_step, d_loss], feed_dict={X: batch_X, z: batch_noise})\n",
    "# Generator 최적화를 수행하고 Generator 손실함수를 return합니다.\n",
    "    _, g_loss_print = sess.run([g_train_step, g_loss], feed_dict={z: batch_noise})\n",
    "# 100번 반복할때마다 Discriminator의 손실함수와 Generator 손실함수를 출력합니다.\n",
    "if i % 100 == 0:\n",
    "    print('반복(Epoch): %d, Generator 손실함수(g_loss): %f, Discriminator 손실함수(d_loss): %f' % (i, g_loss_print, d_loss_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
